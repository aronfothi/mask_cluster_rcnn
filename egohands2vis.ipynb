{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process EgoHands dataset\n",
    "Use part of the \"EgoHands: A Dataset for Hands in Complex Egocentric Interactions\" dataset.\n",
    "\n",
    "\"The EgoHands dataset contains 48 Google Glass videos of complex, first-person interactions between two people.\" This dataset contains mainly of segmentation masks we can convert into bounding boxes.\n",
    "\n",
    "This notebook will download the EgoHands dataset, sample some examples and save results in a standardised way that we can use later.\n",
    "\n",
    "Download the data from http://vision.soic.indiana.edu/egohands_files/egohands_data.zip into ./downloads/ and extract the .zip file before running this notebook.\n",
    "\n",
    "Data will be saved as csv with 2 columns:\n",
    "\n",
    "path: absolute path to image\n",
    "boxes: Boxes as json string. [(ymin, xmin, ymax, ymax) ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "import scipy.io\n",
    "from skimage import measure, io\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from pycocotools import mask\n",
    "\n",
    "np.random.seed(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_DIR = '/media/hdd/aron/egohands/'\n",
    "DATASET_PATH = os.path.join(DOWNLOAD_DIR, '_LABELLED_SAMPLES')\n",
    "TRAINING_FILE = 'train_files.csv'\n",
    "TESTING_FILE = 'test_files.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 folders found.\n"
     ]
    }
   ],
   "source": [
    "# Get all directories with samples\n",
    "sample_directories = [f for f in pathlib.Path(DATASET_PATH).iterdir() if f.is_dir()]\n",
    "print('{} folders found.'.format(len(sample_directories)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_polygons(directory):\n",
    "    \"\"\"\n",
    "    Load polygons from polygons.mat file.\n",
    "    \n",
    "    Args:\n",
    "        (Path): pathlib Path object of directory to load samples from.\n",
    "        \n",
    "    Returns \n",
    "    \"\"\"\n",
    "    # Load polygons file\n",
    "    annotation_path = directory.joinpath('polygons.mat')\n",
    "    mat = scipy.io.loadmat(annotation_path.resolve())\n",
    "    # Load polygons data structure\n",
    "    polygons = mat['polygons'][0]\n",
    "    \n",
    "    return polygons\n",
    "    \n",
    "'''\n",
    "def get_boxes(polygons, frame_idx):\n",
    "    \"\"\"\n",
    "    Get all bounding boxes belonging to a single image.\n",
    "    \n",
    "    Args:\n",
    "        polygons (ndarray): Numpy array containing bounding boxes for each image in a directory\n",
    "            extracted from .mat file struct. Image bounding boxes should follow image order.\n",
    "        frame_idx (int): Index of image in folder (when sorted alphabetically).\n",
    "        \n",
    "    Returns:\n",
    "        [(float, float, float, float)] List of bounding boxes belonging to a sigle image.\n",
    "        Bounding box is represented as (ymin, xmin, ymax, ymax).\n",
    "    \"\"\"\n",
    "    frame_polygons = polygons[frame_idx]\n",
    "    boxes_list = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            poly = frame_polygons[i]\n",
    "        except IndexError:\n",
    "            break\n",
    "        if poly.shape[1] == 2:\n",
    "            xs, ys = zip(*[(int(poly[ci][0]), int(poly[ci][1])) for ci in range(poly.shape[0])])\n",
    "            boxes_list.append((min(ys), min(xs), max(ys), max(xs)))\n",
    "        i += 1\n",
    "    return boxes_list\n",
    "'''\n",
    "\n",
    "i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all samples for each directory\n",
    "def get_path_polygons(directory):\n",
    "    \"\"\"\n",
    "    Get path and boxes represented as string.\n",
    "    \n",
    "    Args:\n",
    "        directory (Path): pathlib Path object of directory to load samples from.\n",
    "        \n",
    "    Returns:\n",
    "        [(str, str)]. List of tuple of (path, boxes as json)\n",
    "    \"\"\"\n",
    "    images_polygons = load_polygons(directory)\n",
    "    return images_polygons\n",
    "    #return [\n",
    "    #    (path.absolute(), polygons_list) for polygons_list, path \n",
    "    #    in zip(images_polygons, sorted(directory.glob('*.jpg'))) if polygons_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hands_info = dict(description= 'Hands', url= 'http://vision.soic.indiana.edu/projects/egohands/', version= '0.1', year= 2020, contributor= 'Indiana', date_created= '2015 00:55:41.903634')\n",
    "hands_licenses = [dict(url= 'https://creativecommons.org/licenses/by/4.0/', id= 1, name= 'Creative Commons Attribution 4.0 License')]\n",
    "hands_categories = [dict(supercategory= 'object', id= 1, name ='hand')]\n",
    "\n",
    "def annotation_data(folders):\n",
    "    hand_data = dict(info=hands_info, \n",
    "                    licenses=hands_licenses,\n",
    "                    categories=hands_categories,\n",
    "                    videos=[],\n",
    "                    annotations=[])\n",
    "    ann_id = 1\n",
    "    vid_id = 1\n",
    "    for directory in folders:\n",
    "        \n",
    "        \n",
    "        img = io.imread(sorted(directory.glob('*.jpg'))[0])\n",
    "        \n",
    "        video_polygons = get_path_polygons(directory)\n",
    "        \n",
    "        video = dict(width= img.shape[1],\n",
    "                     length= len(sorted(directory.glob('*.jpg'))),\n",
    "                     date_captured= '',\n",
    "                     license= '',\n",
    "                     flickr_url= '',\n",
    "                     file_names= [],\n",
    "                     id= vid_id,\n",
    "                     coco_url= '',\n",
    "                     height=img.shape[0]) \n",
    "        \n",
    "        annotations = {}\n",
    "        instance_contours = {}\n",
    "        for i in range(4):\n",
    "            annotations[ann_id] = dict(height= img.shape[0],\n",
    "                                    width= img.shape[1],\n",
    "                                    length= 1,\n",
    "                                    category_id= 1,\n",
    "                                    segmentations= [],\n",
    "                                    bboxes= [],\n",
    "                                    video_id= vid_id,\n",
    "                                    iscrowd= False,\n",
    "                                    id= ann_id,\n",
    "                                    areas= [])\n",
    "            instance_contours[ann_id] = []\n",
    "            \n",
    "            ann_id += 1\n",
    "            \n",
    "                    \n",
    "        for polygons, frame_path in zip(video_polygons, sorted(directory.glob('*.jpg'))):\n",
    "            file_name = str(frame_path).split(os.sep)\n",
    "            \n",
    "            file_name = os.path.join(*file_name[-2:])\n",
    "            \n",
    "            video['file_names'].append(file_name)\n",
    "            \n",
    "            for inst_id, polygon in zip(instance_contours, list(polygons)):\n",
    "                \n",
    "                if polygon.shape[0]>1:\n",
    "                    polygon = polygon.astype(int).astype(float)\n",
    "                    \n",
    "                    \n",
    "                    rles = mask.frPyObjects(polygon,img.shape[0],img.shape[1])\n",
    "                    rle = mask.merge(rles)\n",
    "                    area = mask.area(rle)\n",
    "                    bounding_box = mask.toBbox(rle)\n",
    "                    \n",
    "\n",
    "                    annotations[inst_id]['bboxes'].append(bounding_box.tolist())\n",
    "                    annotations[inst_id]['areas'].append(int(area))\n",
    "\n",
    "                    rle['counts'] = rle['counts'].decode('ascii') \n",
    "                    annotations[inst_id]['segmentations'].append(rle)\n",
    "                    \n",
    "                else:\n",
    "                    annotations[inst_id]['segmentations'].append(None)\n",
    "                    annotations[inst_id]['bboxes'].append(None)\n",
    "                    annotations[inst_id]['areas'].append(None)\n",
    "                    \n",
    "                    \n",
    "            \n",
    "        for _, ann in annotations.items():\n",
    "            hand_data['annotations'].append(ann)\n",
    "            \n",
    "        \n",
    "        vid_id += 1\n",
    "        hand_data['videos'].append(video)\n",
    "        print(vid_id)\n",
    "        \n",
    "    return hand_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "#training_annotation = annotation_data(sample_directories[:8])\n",
    "training_annotation = annotation_data(sample_directories[:40])\n",
    "validation_annotation = annotation_data(sample_directories[40:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/media/hdd/aron/egohands/annotations/instances_train.json', 'w') as outfile:\n",
    "    json.dump(training_annotation, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
